{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ATT Webscraping Members</h1>\n",
    "\n",
    "This jupyter notebook contains the code used to webscrape ATT Members"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing webscraping libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Defining the Webscraping Spider</h2>\n",
    "\n",
    "This code block is defining what our web spider will do - note that it isn't running it, just defining it. See that we are extending the exsiting scrapy.Spider class rather than doing everything from scratch, so we only have minimal coding to do.\n",
    "\n",
    "We tested this code using one page:\n",
    "\n",
    "http://www.accaglobal.com/gb/en/member/find-an-accountant/directory-of-member/results.html?isocountry=GB&FirstName=&Surname=&Location=&inputcountrysuspended=&orgid=ACCA&orby=FNA&ipp=100&pn=1&hid=&requestcount=1\n",
    "\n",
    "ACCA are helpful enough to return the entire details of a member as the search result, so parsing is the only real issue. Annoyingly there are around 200k members, so we will need 2k requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MySpider(scrapy.Spider):\n",
    "    name = \"ATT\"\n",
    "\n",
    "    custom_settings = {\n",
    "        \"RETRY_TIMES\" : 10,\n",
    "        \"RETRY_HTTP_CODES\":[500, 503, 504, 400, 403, 404, 408],\n",
    "        \"DOWNLOADER_MIDDLEWARES\":{'scrapy.downloadermiddlewares.retry.RetryMiddleware': 90,'scrapy_proxies.RandomProxy': 100,'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware': 110},\n",
    "        \"PROXY_LIST\":'/home/de-admin/Documents/Webscraping/proxy_list.txt',\n",
    "        \"PROXY_MODE\": 0\n",
    "    }\n",
    "\n",
    "    def start_requests(self):\n",
    "        \n",
    "        urls = []\n",
    "                \n",
    "        for i in range(6085205,6085205+500*37+1,37):\n",
    "            \n",
    "            url = 'https://core.att.org.uk/Member/memberDetail?pID='+str(i)\n",
    "            urls.append(url)\n",
    "        \n",
    "        for url in urls:\n",
    "            yield scrapy.Request(url=url, callback=self.parse)\n",
    "            \n",
    "    def parse(self, response):\n",
    "        page = [response.url.split(\"/\")[-1]]\n",
    "        details = response.xpath('//ul//text()').extract()\n",
    "        firm_details = [' '.join(a.replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').split()) for a in details]\n",
    "\n",
    "        for i in firm_details:\n",
    "            page.append(i)\n",
    "\n",
    "        full_dt_output.append([page])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running the Webscraping</h2>\n",
    "\n",
    "Note, you can't re run the code below in a single session for one reason or another, so you need to restart the kernel between runs.\n",
    "\n",
    "This code creates a lightweight container for our webspider and then runs it - to be honest understanding this is probably optional unless it breaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-23 18:08:08 [scrapy.utils.log] INFO: Scrapy 1.3.3 started (bot: scrapybot)\n",
      "2017-09-23 18:08:08 [scrapy.utils.log] INFO: Overridden settings: {}\n",
      "2017-09-23 18:08:08 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.logstats.LogStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.corestats.CoreStats']\n",
      "2017-09-23 18:08:08 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy_proxies.RandomProxy',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2017-09-23 18:08:08 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2017-09-23 18:08:08 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2017-09-23 18:08:08 [scrapy.core.engine] INFO: Spider opened\n",
      "2017-09-23 18:08:08 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:08:08 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6042\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://119.235.19.41:3128>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://122.3.29.175:53281>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://5.35.87.190:53281>, 8 proxies left\n",
      "2017-09-23 18:08:08 [scrapy.proxies] DEBUG: Using proxy <http://103.77.10.105:8080>, 8 proxies left\n",
      "2017-09-23 18:08:10 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085390> (referer: None)\n",
      "2017-09-23 18:08:10 [scrapy.proxies] DEBUG: Using proxy <http://109.122.87.33:53281>, 8 proxies left\n",
      "2017-09-23 18:08:11 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085501> (referer: None)\n",
      "2017-09-23 18:08:11 [scrapy.proxies] DEBUG: Using proxy <http://109.122.87.33:53281>, 8 proxies left\n",
      "2017-09-23 18:08:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085353> (referer: None)\n",
      "2017-09-23 18:08:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085316> (referer: None)\n",
      "2017-09-23 18:08:12 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 8 proxies left\n",
      "2017-09-23 18:08:12 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 8 proxies left\n",
      "2017-09-23 18:08:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085427> (referer: None)\n",
      "2017-09-23 18:08:12 [scrapy.proxies] DEBUG: Using proxy <http://103.77.10.105:8080>, 8 proxies left\n",
      "2017-09-23 18:08:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085464> (referer: None)\n",
      "2017-09-23 18:08:12 [scrapy.proxies] DEBUG: Using proxy <http://109.122.87.33:53281>, 8 proxies left\n",
      "2017-09-23 18:08:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085612> (referer: None)\n",
      "2017-09-23 18:08:13 [scrapy.proxies] DEBUG: Using proxy <http://119.235.19.41:3128>, 8 proxies left\n",
      "2017-09-23 18:08:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085686> (referer: None)\n",
      "2017-09-23 18:08:13 [scrapy.proxies] DEBUG: Using proxy <http://103.77.10.105:8080>, 8 proxies left\n",
      "2017-09-23 18:08:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085723> (referer: None)\n",
      "2017-09-23 18:08:15 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 8 proxies left\n",
      "2017-09-23 18:08:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085760> (referer: None)\n",
      "2017-09-23 18:08:16 [scrapy.proxies] DEBUG: Using proxy <http://103.77.10.105:8080>, 8 proxies left\n",
      "2017-09-23 18:08:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085205> (referer: None)\n",
      "2017-09-23 18:08:20 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 8 proxies left\n",
      "2017-09-23 18:08:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085871> (referer: None)\n",
      "2017-09-23 18:08:21 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 8 proxies left\n",
      "2017-09-23 18:09:08 [scrapy.extensions.logstats] INFO: Crawled 12 pages (at 12 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:09:22 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 7 proxies left\n",
      "2017-09-23 18:09:22 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085834> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:09:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085945> (referer: None)\n",
      "2017-09-23 18:09:23 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 7 proxies left\n",
      "2017-09-23 18:09:24 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 7 proxies left\n",
      "2017-09-23 18:09:24 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085797> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:09:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086019> (referer: None)\n",
      "2017-09-23 18:09:25 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 7 proxies left\n",
      "2017-09-23 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086056> (referer: None)\n",
      "2017-09-23 18:09:26 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 7 proxies left\n",
      "2017-09-23 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086093> (referer: None)\n",
      "2017-09-23 18:09:26 [scrapy.proxies] DEBUG: Using proxy <http://5.35.87.190:53281>, 7 proxies left\n",
      "2017-09-23 18:09:26 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086130> (referer: None)\n",
      "2017-09-23 18:09:26 [scrapy.proxies] DEBUG: Using proxy <http://103.77.10.105:8080>, 7 proxies left\n",
      "2017-09-23 18:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086167> (referer: None)\n",
      "2017-09-23 18:09:27 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 7 proxies left\n",
      "2017-09-23 18:09:27 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086204> (referer: None)\n",
      "2017-09-23 18:09:27 [scrapy.proxies] DEBUG: Using proxy <http://14.141.216.6:3128>, 7 proxies left\n",
      "2017-09-23 18:10:08 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 7 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:10:17 [scrapy.proxies] INFO: Removing failed proxy <http://122.3.29.175:53281>, 6 proxies left\n",
      "2017-09-23 18:10:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085242> (failed 1 times): TCP connection timed out: 110: Connection timed out.\n",
      "2017-09-23 18:10:33 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 6 proxies left\n",
      "2017-09-23 18:10:33 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085982> (failed 1 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:11:08 [scrapy.extensions.logstats] INFO: Crawled 19 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:11:08 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:11:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085279> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085279 took longer than 180.0 seconds..\n",
      "2017-09-23 18:11:08 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086278> (referer: None)\n",
      "2017-09-23 18:11:08 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 5 proxies left\n",
      "2017-09-23 18:11:11 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:11:11 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085538> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085538 took longer than 180.0 seconds..\n",
      "2017-09-23 18:11:12 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:11:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085575> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085575 took longer than 180.0 seconds..\n",
      "2017-09-23 18:11:12 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:11:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085649> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085649 took longer than 180.0 seconds..\n",
      "2017-09-23 18:11:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086352> (referer: None)\n",
      "2017-09-23 18:11:12 [scrapy.proxies] DEBUG: Using proxy <http://5.35.87.190:53281>, 5 proxies left\n",
      "2017-09-23 18:11:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086426> (referer: None)\n",
      "2017-09-23 18:11:13 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 5 proxies left\n",
      "2017-09-23 18:11:13 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086389> (referer: None)\n",
      "2017-09-23 18:11:13 [scrapy.proxies] DEBUG: Using proxy <http://185.104.70.82:53281>, 5 proxies left\n",
      "2017-09-23 18:11:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6085242> (referer: None)\n",
      "2017-09-23 18:11:18 [scrapy.proxies] DEBUG: Using proxy <http://5.35.87.190:53281>, 5 proxies left\n",
      "2017-09-23 18:11:21 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:11:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085908> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085908 took longer than 180.0 seconds..\n",
      "2017-09-23 18:11:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086500> (referer: None)\n",
      "2017-09-23 18:11:21 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 5 proxies left\n",
      "2017-09-23 18:11:54 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 5 proxies left\n",
      "2017-09-23 18:11:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085797> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:12:08 [scrapy.extensions.logstats] INFO: Crawled 25 pages (at 6 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:12:27 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 5 proxies left\n",
      "2017-09-23 18:12:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085834> (failed 2 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085834 took longer than 180.0 seconds..\n",
      "2017-09-23 18:12:36 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 5 proxies left\n",
      "2017-09-23 18:12:36 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085982> (failed 2 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:12:36 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086537> (referer: None)\n",
      "2017-09-23 18:12:36 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 5 proxies left\n",
      "2017-09-23 18:12:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086574> (referer: None)\n",
      "2017-09-23 18:12:37 [scrapy.proxies] DEBUG: Using proxy <http://5.35.87.190:53281>, 5 proxies left\n",
      "2017-09-23 18:12:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086611> (referer: None)\n",
      "2017-09-23 18:12:37 [scrapy.proxies] DEBUG: Using proxy <http://5.35.87.190:53281>, 5 proxies left\n",
      "2017-09-23 18:12:37 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086648> (referer: None)\n",
      "2017-09-23 18:12:37 [scrapy.proxies] DEBUG: Using proxy <http://41.159.141.179:8080>, 5 proxies left\n",
      "2017-09-23 18:13:02 [scrapy.crawler] INFO: Received SIGINT, shutting down gracefully. Send again to force \n",
      "2017-09-23 18:13:02 [scrapy.core.engine] INFO: Closing spider (shutdown)\n",
      "2017-09-23 18:13:08 [scrapy.extensions.logstats] INFO: Crawled 29 pages (at 4 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:13:17 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:13:17 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6086241> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6086241 took longer than 180.0 seconds..\n",
      "2017-09-23 18:13:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086685> (referer: None)\n",
      "2017-09-23 18:14:08 [scrapy.extensions.logstats] INFO: Crawled 30 pages (at 1 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:14:08 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:14:08 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6086315> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6086315 took longer than 180.0 seconds..\n",
      "2017-09-23 18:14:12 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:14:12 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6086463> (failed 1 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6086463 took longer than 180.0 seconds..\n",
      "2017-09-23 18:14:18 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:14:18 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085279> (failed 2 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085279 took longer than 180.0 seconds..\n",
      "2017-09-23 18:14:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086722> (referer: None)\n",
      "2017-09-23 18:14:18 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086759> (referer: None)\n",
      "2017-09-23 18:14:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086796> (referer: None)\n",
      "2017-09-23 18:14:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://core.att.org.uk/Member/memberDetail?pID=6086833> (referer: None)\n",
      "2017-09-23 18:14:21 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:14:21 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085538> (failed 2 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085538 took longer than 180.0 seconds..\n",
      "2017-09-23 18:14:24 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 5 proxies left\n",
      "2017-09-23 18:14:24 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085797> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:14:24 [scrapy.core.scraper] ERROR: Error downloading <GET https://core.att.org.uk/Member/memberDetail?pID=6085797>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:14:54 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:14:54 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085575> (failed 2 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085575 took longer than 180.0 seconds..\n",
      "2017-09-23 18:15:08 [scrapy.extensions.logstats] INFO: Crawled 34 pages (at 4 pages/min), scraped 0 items (at 0 items/min)\n",
      "2017-09-23 18:15:14 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 5 proxies left\n",
      "2017-09-23 18:15:14 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085834> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:15:14 [scrapy.core.scraper] ERROR: Error downloading <GET https://core.att.org.uk/Member/memberDetail?pID=6085834>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:15:21 [scrapy.proxies] INFO: Removing failed proxy <http://109.122.87.33:53281>, 5 proxies left\n",
      "2017-09-23 18:15:21 [scrapy.downloadermiddlewares.retry] DEBUG: Gave up retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085982> (failed 3 times): [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:15:21 [scrapy.core.scraper] ERROR: Error downloading <GET https://core.att.org.uk/Member/memberDetail?pID=6085982>: [<twisted.python.failure.Failure OpenSSL.SSL.Error: [('SSL routines', 'SSL23_GET_SERVER_HELLO', 'unknown protocol')]>]\n",
      "2017-09-23 18:15:27 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:15:27 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085649> (failed 2 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085649 took longer than 180.0 seconds..\n",
      "2017-09-23 18:15:37 [scrapy.proxies] INFO: Removing failed proxy <http://14.141.216.6:3128>, 5 proxies left\n",
      "2017-09-23 18:15:37 [scrapy.downloadermiddlewares.retry] DEBUG: Retrying <GET https://core.att.org.uk/Member/memberDetail?pID=6085908> (failed 2 times): User timeout caused connection failure: Getting https://core.att.org.uk/Member/memberDetail?pID=6085908 took longer than 180.0 seconds..\n",
      "2017-09-23 18:15:37 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/exception_count': 23,\n",
      " 'downloader/exception_type_count/twisted.internet.error.TCPTimedOutError': 1,\n",
      " 'downloader/exception_type_count/twisted.internet.error.TimeoutError': 14,\n",
      " 'downloader/exception_type_count/twisted.web._newclient.ResponseNeverReceived': 8,\n",
      " 'downloader/request_bytes': 13908,\n",
      " 'downloader/request_count': 57,\n",
      " 'downloader/request_method_count/GET': 57,\n",
      " 'downloader/response_bytes': 15523,\n",
      " 'downloader/response_count': 34,\n",
      " 'downloader/response_status_count/200': 34,\n",
      " 'finish_reason': 'shutdown',\n",
      " 'finish_time': datetime.datetime(2017, 9, 23, 17, 15, 37, 725069),\n",
      " 'log_count/DEBUG': 103,\n",
      " 'log_count/ERROR': 3,\n",
      " 'log_count/INFO': 38,\n",
      " 'response_received_count': 34,\n",
      " 'scheduler/dequeued': 57,\n",
      " 'scheduler/dequeued/memory': 57,\n",
      " 'scheduler/enqueued': 65,\n",
      " 'scheduler/enqueued/memory': 65,\n",
      " 'start_time': datetime.datetime(2017, 9, 23, 17, 8, 8, 67494)}\n",
      "2017-09-23 18:15:37 [scrapy.core.engine] INFO: Spider closed (shutdown)\n"
     ]
    }
   ],
   "source": [
    "full_dt_output = []\n",
    "\n",
    "process = CrawlerProcess()\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now downloaded all the pages that we want to scrape. The first thing to do is to examine what we got back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['memberDetail?pID=6085390', '', u'Mr Matthew Benjamin Davies ATT', '', '', u'LONDON', u'SW12 8BJ', '']], [['memberDetail?pID=6085501', '', u'Mr Christopher Smith CTA ATT', '', '', u'Leathers the Accountants', u'Cale Cross House', u'156 Pilgrim Street', u'NEWCASTLE UPON TYNE', u'NE1 6SU', u'Email: c.smith@leathersllp.co.uk', u'Tel: 0181 224 6760', u'Specialisms: Corporation Tax Returns', '']], [['memberDetail?pID=6085353', '', u'Mr Philip Edward Grange ATT', '', '', u'NEWCASTLE UPON TYNE', u'NE13 9AA', '']], [['memberDetail?pID=6085316', '', u'Mrs Nicola McReynolds CTA ATT', '', '', u'Henry Brown & Co.', u'26 Portland Road', u'KILMARNOCK', u'East Ayrshire', u'KA1 2EB', u'Email: nmcreynolds@henrybrown.co.uk', u'Tel: 01563522308', u'Specialisms: Capital Allowances, Capital Gains Tax, Child Benefit, Corporation Tax Returns, Employer Compliance , Income Tax, International Tax, Investigations, Compliance Checks, National Insurance, Non-Resident Landlord Registration and Tax Returns, Partnership Registration and Tax Returns, Payroll, Pensions, Rental Income, Self Assessment Registration and Tax Returns, Self-Employed Registration and Tax Returns, Selling a Property, Starting a Business, Tax Credits, Trusts, Estates and Inheritance Tax, UK Personal Tax, UK Tax Planning, VAT Registration and Returns', '']], [['memberDetail?pID=6085427', '', u'Mr Neil Stephen Kimber', '', '', u'EASTLEIGH', u'SO50 9AL', '']], [['memberDetail?pID=6085464', '', u'Miss Anna Waldron ATT', '', '', u'BRISTOL', u'BS1 6BX', '']], [['memberDetail?pID=6085612', '', u'Mrs Louise May Kaemena CTA ATT', '', '', u'GATWICK', u'West Sussex', u'RH6 0PA', '']], [['memberDetail?pID=6085686', '', u'Miss Shelley Farrington CTA', '', '', u'READING', u'RG1 3EX', '']], [['memberDetail?pID=6085723', '', u'Mr Chegezo Ndimuchaga Kilahala', '', '', u'READING', u'RG6 1NJ', '']], [['memberDetail?pID=6085760', '', u'Mr Matthew David Foddy CTAATT', '', '', u'Grant Thornton', u'Royal Liver Building', u'LIVERPOOL', u'L3 1PS', u'Email: matt.foddy@uk.gt.com', u'Tel: 0151 224 0839', u'Specialisms: Corporation Tax Returns', '']], [['memberDetail?pID=6085205', '', u'Mrs Vicky Aggarwal CTA ATT', '', '', u'Phoenix Life', u'1 Wythall Green Way', u'Wythall', u'BIRMINGHAM', u'B47 6WG', u'Email: vicky_aggarwal@hotmail.co.uk', u'Tel: 02035679821', u'Specialisms: Corporation Tax Returns', '']], [['memberDetail?pID=6085871', '', u'Mr John Hiscox', '', '', u'STOCKPORT', u'SK7 2BY', '']], [['memberDetail?pID=6085945', '', u'Mrs Cordelia Fitzgerald', '', '', u'PETERBOROUGH', u'PE3 8JN', '']], [['memberDetail?pID=6086019', '', u'Miss Amy Joy Tanner ATT', '', '', u'DRE & Co', u'6 Claremont Buildings', u'Claremont Bank', u'SHREWSBURY', u'Shropshire', u'SY1 1RJ', u'Email: aj-tanner@hotmail.co.uk', u'Tel: 01743 241581', u'Specialisms: Corporation Tax Returns, National Insurance, UK Personal Tax', '']], [['memberDetail?pID=6086056', '', u'Mrs June Pearl Barnaby', '', '', u'TUNBRIDGE WELLS', u'TN5 6UD', '']], [['memberDetail?pID=6086093', '', u'Miss Tracey Jacqueline Mould', '', '', u'LEICESTER', u'LE1 7NH', '']], [['memberDetail?pID=6086130', '', u'Mr Stephen Robinson', '', '', u'SHEFFIELD', u'S11 9NN', '']], [['memberDetail?pID=6086167', '', u'Miss Cherie Louise Mangham CTA', '', '', u'55 Little Gaynes Lane', u'UPMINSTER', u'RM142JR', u'Email: cheriemangham@live.co.uk', u'Specialisms:', '']], [['memberDetail?pID=6086204', '', u'Miss Yen Ny Yee', '', '', u'LONDON', u'SE1 3HA', '']], [['memberDetail?pID=6086278', '', u'Miss Pa Pa Win', '', '', u'LONDON', u'N3 1XE', '']], [['memberDetail?pID=6086352', '', u'Miss Rachel Dillon', '', '', u'DUBLIN 2', '']], [['memberDetail?pID=6086426', '', u'Miss Linda Anne Melville', '', '', u'PERTH', u'Perthshire', u'PH1 5JN', '']], [['memberDetail?pID=6086389', '', u'Mrs Yeshi Demelash Abay', '', '', u'LONDON', u'W6 9EL', '']], [['memberDetail?pID=6085242', '', u'Mr Wilson Cotton', '', '', u'LONDON', u'EC2R6AY', '']], [['memberDetail?pID=6086500', '', u'Mr Charles Edward Yorke', '', '', u'LONDON', u'EC4M 7WS', '']], [['memberDetail?pID=6086537', '', u'Mr Ahmad Makhdoom Salman', '', '', u'GLASGOW', u'G40 1BZ', '']], [['memberDetail?pID=6086574', '', u'Miss Mariya Rajput', '', '', u'BIRMINGHAM', u'West Midlands', u'B16 9HS', '']], [['memberDetail?pID=6086611', '', u'Mrs Sarah Elisabeth Kaye', '', '', u'HEREFORD', u'Herefordshire', u'HR4 0BG', '']], [['memberDetail?pID=6086648', '', u'Mr Alan Boby', '', '', u'BANBURY', u'OX16 9RZ', '']], [['memberDetail?pID=6086685', '', u'Miss Valliammai Janaki Manian CTA ATT', '', '', u'YARM', u'Cleveland', u'TS15 9SP', '']], [['memberDetail?pID=6086722', '', u'Mrs Claire Marie Base ATT', '', '', u'CHELTENHAM', u'GL53 7LS', '']], [['memberDetail?pID=6086759', '', u'Miss Abigail Langdown', '', '', u'STURMINSTER NEWTON', u'DT10 1AS', '']], [['memberDetail?pID=6086796', '', u'Mrs Marie Bawden', '', '', u'WARWICK', u'CV34 5JW', '']], [['memberDetail?pID=6086833', '', u'Mr Ewan Williamson', '', '', u'PENRITH', u'Cumbria', u'CA11 7HW', '']]]\n"
     ]
    }
   ],
   "source": [
    "print(full_dt_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ce882a1bec00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dt_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dt_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfinal_dt_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dt_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_dt_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "final_dt_output = []\n",
    "\n",
    "for i in range(len(full_dt_output)):\n",
    "    for j in range(len(full_dt_output[i])):\n",
    "        final_dt_output.append(full_dt_output[i][j].encode('ascii','replace'))\n",
    "\n",
    "print(final_dt_output[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "row_index_fm = []\n",
    "row_index_tn = []\n",
    "row_index_co = []\n",
    "row_index_yr = []\n",
    "row_index_ct = []\n",
    "\n",
    "for i in range(len(final_fm_output)):\n",
    "    if \"rowId\" in final_fm_output[i]:\n",
    "        row_index_fm.append(i)\n",
    "\n",
    "for i in range(len(final_tn_output)):\n",
    "    if \"rowId\" in final_tn_output[i]:\n",
    "        row_index_tn.append(i)\n",
    "\n",
    "for i in range(len(final_co_output)):\n",
    "    if \"rowId\" in final_co_output[i]:\n",
    "        row_index_co.append(i)\n",
    "\n",
    "for i in range(len(final_yr_output)):\n",
    "    if \"rowId\" in final_yr_output[i]:\n",
    "        row_index_yr.append(i)\n",
    "\n",
    "for i in range(len(final_ct_output)):\n",
    "    if \"rowId\" in final_ct_output[i]:\n",
    "        row_index_ct.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "split_output_fm = []\n",
    "split_output_tn = []\n",
    "split_output_co = []\n",
    "split_output_yr = []\n",
    "split_output_ct = []\n",
    "\n",
    "start = 0\n",
    "for index in row_index_fm[1:]:\n",
    "    split_output_fm.append(final_fm_output[start+1:index])\n",
    "    start = index\n",
    "    \n",
    "split_output_fm.append(final_fm_output[start+1:])\n",
    "\n",
    "start = 0\n",
    "for index in row_index_tn[1:]:\n",
    "    split_output_tn.append(final_tn_output[start+1:index])\n",
    "    start = index\n",
    "    \n",
    "split_output_tn.append(final_tn_output[start+1:])\n",
    "\n",
    "start = 0\n",
    "for index in row_index_co[1:]:\n",
    "    split_output_co.append(final_co_output[start+1:index])\n",
    "    start = index\n",
    "    \n",
    "split_output_co.append(final_co_output[start+1:])\n",
    "\n",
    "start = 0\n",
    "for index in row_index_yr[1:]:\n",
    "    split_output_yr.append(final_yr_output[start+1:index])\n",
    "    start = index\n",
    "    \n",
    "split_output_yr.append(final_yr_output[start+1:])\n",
    "\n",
    "start = 0\n",
    "for index in row_index_ct[1:]:\n",
    "    split_output_ct.append(final_ct_output[start+1:index])\n",
    "    start = index\n",
    "    \n",
    "split_output_ct.append(final_ct_output[start+1:])\n",
    "\n",
    "print(split_output_fm[0:5])\n",
    "print(split_output_tn[0:5])\n",
    "print(split_output_co[0:5])\n",
    "print(split_output_yr[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "final_fm = []   \n",
    "for i in range(len(split_output_fm)):\n",
    "    fm = []\n",
    "    \n",
    "    for j in range(len(split_output_fm[i])):\n",
    "        if split_output_fm[i][j]:\n",
    "            fm.append(split_output_fm[i][j].encode('ascii','replace'))\n",
    "            \n",
    "    final_fm.append(fm)\n",
    "\n",
    "final_tn = []\n",
    "for a in split_output_tn:\n",
    "    if a:\n",
    "        final_tn.append(a[0])\n",
    "    else:\n",
    "        final_tn.append(\"\")\n",
    "\n",
    "final_co = []\n",
    "for a in split_output_co:\n",
    "    if a:\n",
    "        final_co.append(a[0])\n",
    "    else:\n",
    "        final_co.append(\"\")\n",
    "\n",
    "final_yr = []\n",
    "for a in split_output_yr:\n",
    "    if a:\n",
    "        final_yr.append(int(a[0]))\n",
    "    else:\n",
    "        final_yr.append(None)\n",
    "\n",
    "final_ct = []   \n",
    "for i in range(len(split_output_ct)):\n",
    "    ct = []\n",
    "    \n",
    "    for j in range(len(split_output_ct[i])):\n",
    "        if split_output_ct[i][j]:\n",
    "            ct.append(split_output_ct[i][j].encode('ascii','replace'))\n",
    "            \n",
    "    final_ct.append(ct)\n",
    "\n",
    "\n",
    "final_nm = []\n",
    "final_ty = []\n",
    "for i in final_fm:\n",
    "    final_nm.append(i[0])\n",
    "    final_ty.append(i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "members_matrix_ACCA = []\n",
    "\n",
    "for i in range(len(final_nm)):\n",
    "    members_matrix_ACCA.append([final_nm[i],final_ty[i],final_tn[i],final_co[i],final_yr[i],final_ct[i]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(members_matrix_ACCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "f = open('/home/de-admin/Documents/Webscraping/ACCA_Firms.txt', 'w')\n",
    "\n",
    "for item in firms_matrix_ACCA:\n",
    "    print>>f, item\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
